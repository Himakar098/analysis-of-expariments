---
title: "practice test 2"
author: "krish"
date: "2024-05-09"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.



```{r}
# Load the dataset
Time <- c(78.8, 309.5, 184.5, 69.6, 68.8, 95.7, 112.3, 171.9, 177.8, 65.8, 51.2, 59.6, 85.4, 138.1, 125.7, 70.1, 342.9, 70.3, 124.9, 90, 111.7, 104.7, 82.1, 199.8, 256.9, 179.7, 296.6, 159.6, 182.1, 173, 216, 329.8, 325.3, 47.8, 57, 59.4, 59.2, 84.4, 202.1, 46.6, 257.5, 167.1, 418.1, 302.2, 87.2)
DArea <- c(3.6, 5.33, 6.29, 2.2, 1.44, 5.4, 6.6, 7.9, 4.88, 0.85, 1.45, 4.1, 3.89, 5.48, 5.48, 3.78, 19.58, 1.5, 4.83, 1.89, 3.43, 33.18, 4.22, 7.43, 9.98, 22.53, 45, 10.36, 10.36, 22.5, 23.07, 42.67, 30.67, 1.01, 2.52, 2.16, 2.14, 7.74, 13.65, 4.22, 20.73, 7.48, 7.21, 10.89, 3.24)
CCost <- c(82.4, 422.3, 179.8, 100, 103, 134.4, 173.2, 207.9, 327.7, 56.2, 46.8, 118.9, 113.3, 309, 309, 106.1, 374.5, 98.3, 99.3, 60, 67.4, 1123.6, 123.6, 222.9, 498, 563.3, 749.1, 187.3, 187.3, 500.5, 701.7, 1066.8, 766.7, 30, 65.5, 63.7, 68.4, 187.3, 421.4, 107.7, 1264.1, 220.1, 336.2, 641.4, 70.2)
Dwgs <- c(6, 12, 9, 5, 5, 5, 5, 7, 9, 3, 3, 6, 6, 6, 6, 5, 7, 5, 6, 5, 5, 9, 6, 9, 15, 9, 9, 10, 10, 9, 12, 12, 15, 4, 5, 5, 4, 5, 9, 6, 11, 7, 11, 8, 6)
Length <- c(90, 126, 78, 60, 60, 60, 180, 188, 336, 25, 50, 114, 108, 128, 128, 90, 430, 50, 68, 64, 70, 273, 95, 73, 185, 395, 450, 140, 140, 308, 438, 405, 902, 35, 70, 60, 70, 242, 369, 124, 860, 220, 285, 560, 90)
Spans <- c(1, 2, 1, 1, 1, 1, 3, 2, 2, 1, 1, 2, 2, 2, 2, 1, 6, 1, 1, 1, 1, 2, 1, 1, 3, 6, 5, 3, 3, 3, 4, 4, 7, 1, 1, 1, 1, 5, 1, 1, 5, 3, 3, 5, 1)

# Create the dataset
bridge <- data.frame(Time, DArea, CCost, Dwgs, Length, Spans)

# Apply log transformation to the variables
bridge_log <- log(bridge)

# Fit the full model
full_model <- lm(Time ~ ., data = bridge_log)

# Perform backward selection
backward_model <- step(full_model, direction = "backward")

# Get the AIC value of the final model
final_AIC <- AIC(backward_model)

# Get the names of the variables in the final model
selected_variables <- formula(backward_model)

# Print the final AIC value and the selected variables
print(final_AIC)
print(selected_variables)


```

```{r}
# Load data into R
Time <- c(78.8, 309.5, 184.5, 69.6, 68.8, 95.7, 112.3, 171.9, 177.8, 65.8, 51.2, 59.6, 85.4, 138.1, 125.7, 70.1, 342.9, 70.3, 124.9, 90, 111.7, 104.7, 82.1, 199.8, 256.9, 179.7, 296.6, 159.6, 182.1, 173, 216, 329.8, 325.3, 47.8, 57, 59.4, 59.2, 84.4, 202.1, 46.6, 257.5, 167.1, 418.1, 302.2, 87.2)
DArea <- c(3.6, 5.33, 6.29, 2.2, 1.44, 5.4, 6.6, 7.9, 4.88, 0.85, 1.45, 4.1, 3.89, 5.48, 5.48, 3.78, 19.58, 1.5, 4.83, 1.89, 3.43, 33.18, 4.22, 7.43, 9.98, 22.53, 45, 10.36, 10.36, 22.5, 23.07, 42.67, 30.67, 1.01, 2.52, 2.16, 2.14, 7.74, 13.65, 4.22, 20.73, 7.48, 7.21, 10.89, 3.24)
CCost <- c(82.4, 422.3, 179.8, 100, 103, 134.4, 173.2, 207.9, 327.7, 56.2, 46.8, 118.9, 113.3, 309, 309, 106.1, 374.5, 98.3, 99.3, 60, 67.4, 1123.6, 123.6, 222.9, 498, 563.3, 749.1, 187.3, 187.3, 500.5, 701.7, 1066.8, 766.7, 30, 65.5, 63.7, 68.4, 187.3, 421.4, 107.7, 1264.1, 220.1, 336.2, 641.4, 70.2)
Dwgs <- c(6, 12, 9, 5, 5, 5, 5, 7, 9, 3, 3, 6, 6, 6, 6, 5, 7, 5, 6, 5, 5, 9, 6, 9, 15, 9, 9, 10, 10, 9, 12, 12, 15, 4, 5, 5, 4, 5, 9, 6, 11, 7, 11, 8, 6)
Length <- c(90, 126, 78, 60, 60, 60, 180, 188, 336, 25, 50, 114, 108, 128, 128, 90, 430, 50, 68, 64, 70, 273, 95, 73, 185, 395, 450, 140, 140, 308, 438, 405, 902, 35, 70, 60, 70, 242, 369, 124, 860, 220, 285, 560, 90)
Spans <- c(1, 2, 1, 1, 1, 1, 3, 2, 2, 1, 1, 2, 2, 2, 2, 1, 6, 1, 1, 1, 1, 2, 1, 1, 3, 6, 5, 3, 3, 3, 4, 4, 7, 1, 1, 1, 1, 5, 1, 1, 5, 3, 3, 5, 1)

# Create the data frame
bridge <- data.frame(Time, DArea, CCost, Dwgs, Length, Spans)

# Apply log transformation
bridge_log <- log(bridge)

# Fit the full model
full_model <- lm(log(Time) ~ ., data=bridge_log)

# Perform backward elimination
reduced_model <- step(full_model, direction="backward")

# Show the final model and AIC
summary(reduced_model)
AIC(reduced_model)

```

```{r}
# Create the dataset
salary <- data.frame(
  salary = c(33.2, 40.3, 38.7, 46.8, 41.4, 37.5, 39, 40.7, 30.1, 52.9, 38.2, 31.8, 43.3, 44.1, 42.8, 33.6, 34.2, 48),
  quality = c(3.5, 5.3, 5.1, 5.8, 4.2, 6, 6.8, 5.5, 3.1, 7.2, 4.5, 4.9, 8, 6.5, 6.6, 3.7, 6.2, 7),
  experience = c(9, 20, 18, 33, 31, 13, 25, 30, 5, 47, 25, 11, 23, 35, 39, 21, 7, 40),
  publish = c(6.1, 6.4, 7.4, 6.7, 7.5, 5.9, 6, 4, 5.8, 8.3, 5, 6.4, 7.6, 7, 5, 4.4, 5.5, 7)
)

# Fit the multiple linear regression model
model <- lm(salary ~ ., data = salary)

# Print the summary of the model
summary(model)

```

```{r}
sales=c(1843.01 ,134.48 ,469.66 ,467.65 ,2626.07 ,805.89 ,909.5 ,77.77 ,1793.48 ,217.96 ,453.84 ,938.11 ,1962.19 ,2579.76 ,198.14 ,303.88 ,2361.85 ,949.87 ,360.61 ,2016.32 ,113.4 ,292.88 ,1386.37 ,140.51 ,387.87 ,551.11 ,284.24 ,341.5 ,299.84 ,151.12 ,68.64 ,1471.59 ,535.11 ,1642.11 ,370.22 ,249.12 ,557.65 ,236.64 ,112.87 ,674.44 ,1490.8 ,131.47 ,458.77 ,489.61 ,1659.04 ,1033.81 ,719.45 ,398.82 ,211.93 ,279.49 ,340.24 ,1098.96 ,1095.93 ,518.03 ,215.41 ,335.44 ,261.72 ,567.37 ,1355.82 ,339.61 ,350.2 ,1046.59 ,1203.1 ,1228.47 ,2791.35 ,992.64 ,232.92 ,288.3 ,209.14 ,342.31 ,484.31 ,107.77 ,1323.47 ,850.19 ,372.22 ,906.26 ,575.31 ,317.53 ,2279.96 ,638.49 ,591.37 ,1676.22 ,398.68 ,1458.04 ,152.77 ,1369.59 ,104.65 ,188.18 ,705.16 ,962.18 ,262.06 ,374.37 ,2093.83 ,246.62 ,458.35 ,996.14 ,495.68 ,411.5 ,143.29 ,1542.81)
adexp=c(950.1 ,231.1 ,606.8 ,486 ,891.3 ,762.1 ,456.5 ,18.5 ,821.4 ,444.7 ,615.4 ,791.9 ,921.8 ,738.2 ,176.3 ,405.7 ,935.5 ,916.9 ,410.3 ,893.6 ,57.9 ,352.9 ,813.2 ,9.9 ,138.9 ,202.8 ,198.7 ,603.8 ,272.2 ,198.8 ,15.3 ,746.8 ,445.1 ,931.8 ,466 ,418.6 ,846.2 ,525.2 ,202.6 ,672.1 ,838.1 ,19.6 ,681.3 ,379.5 ,831.8 ,502.8 ,709.5 ,428.9 ,304.6 ,189.7 ,193.4 ,682.2 ,302.8 ,541.7 ,150.9 ,697.9 ,378.4 ,860 ,853.7 ,593.6 ,496.6 ,899.8 ,821.6 ,644.9 ,818 ,660.2 ,342 ,289.7 ,341.2 ,534.1 ,727.1 ,309.3 ,838.5 ,568.1 ,370.4 ,702.7 ,546.6 ,444.9 ,694.6 ,621.3 ,794.8 ,956.8 ,522.6 ,880.1 ,173 ,979.7 ,271.4 ,252.3 ,875.7 ,737.3 ,136.5 ,11.8 ,893.9 ,199.1 ,298.7 ,661.4 ,284.4 ,469.2 ,64.8 ,988.3)
# Step 1: Fit a linear regression model to the original data
model_original <- lm(sales ~ adexp)
summary(model_original)
model_transformed <- lm(log(sales) ~ adexp)
summary(model_transformed)
plot(model_transformed)


# Step 6: Calculate Cook's distance for each observation
cooks_distance1 <- cooks.distance(model_original)
cooks_distance <- cooks.distance(model_transformed)
head(cooks_distance)
plot(cooks_distance ~ adexp, xlab = "Ad Exp", ylab = "Cook's distance")
# Step 8: Determine the cutoff value for Cook's distance
n <- length(log(sales))

cutoff <- 4 / (n - 2)
abline(h=cutoff, col="red")
sort(cooks_distance)


```
```{r}
salary<-c(33.2,40.3,38.7,46.8,41.4,37.5,39,40.7,30.1,52.9,38.2,31.8,43.3,44.1,42.8,33.6,34.2,48)
quality <-c(3.5,5.3,5.1,5.8,4.2,6,6.8,5.5,3.1,7.2,4.5,4.9,8,6.5,6.6,3.7,6.2,7)
experience <- c(9,20,18,33,31,13,25,30,5,47,25,11,23,35,39,21,7,40)
publish <-c(6.1,6.4,7.4,6.7,7.5,5.9,6,4,5.8,8.3,5,6.4,7.6,7,5,4.4,5.5,7)
salary <- data.frame(salary, quality,experience,publish)
head(salary)

# Perform forward selection
model <- lm(salary ~ 1, data = salary)  # Start with an intercept-only model
forward_model <- step(model, direction = "forward", scope = formula(~ quality + experience + publish))

# Get the AIC at initial and final steps
aic_initial <- AIC(model)
aic_final <- AIC(forward_model)

# Output the results
print(paste("The value of AIC at initial step is:", aic_initial))
print(paste("The value of AIC at the final step is:", aic_final))
```
```{r}
# Install and load the leaps package if not already installed
if (!requireNamespace("leaps", quietly = TRUE)) {
  install.packages("leaps")
}
library(leaps)

# Load the data
Time <- c(78.8,309.5,184.5,69.6,68.8,95.7,112.3,171.9,177.8,65.8,51.2,59.6,85.4,138.1,125.7,70.1,342.9,70.3,124.9,90,111.7,104.7,82.1,199.8,256.9,179.7,296.6,159.6,182.1,173,216,329.8,325.3,47.8,57,59.4,59.2,84.4,202.1,46.6,257.5,167.1,418.1,302.2,87.2)
DArea <- c(3.6,5.33,6.29,2.2,1.44,5.4,6.6,7.9,4.88,0.85,1.45,4.1,3.89,5.48,5.48,3.78,19.58,1.5,4.83,1.89,3.43,33.18,4.22,7.43,9.98,22.53,45,10.36,10.36,22.5,23.07,42.67,30.67,1.01,2.52,2.16,2.14,7.74,13.65,4.22,20.73,7.48,7.21,10.89,3.24)
CCost <- c(82.4,422.3,179.8,100,103,134.4,173.2,207.9,327.7,56.2,46.8,118.9,113.3,309,309,106.1,374.5,98.3,99.3,60,67.4,1123.6,123.6,222.9,498,563.3,749.1,187.3,187.3,500.5,701.7,1066.8,766.7,30,65.5,63.7,68.4,187.3,421.4,107.7,1264.1,220.1,336.2,641.4,70.2)
Dwgs <- c(6,12,9,5,5,5,5,7,9,3,3,6,6,6,6,5,7,5,6,5,5,9,6,9,15,9,9,10,10,9,12,12,15,4,5,5,4,5,9,6,11,7,11,8,6)
Length <- c(90,126,78,60,60,60,180,188,336,25,50,114,108,128,128,90,430,50,68,64,70,273,95,73,185,395,450,140,140,308,438,405,902,35,70,60,70,242,369,124,860,220,285,560,90)
Spans <- c(1,2,1,1,1,1,3,2,2,1,1,2,2,2,2,1,6,1,1,1,1,2,1,1,3,6,5,3,3,3,4,4,7,1,1,1,1,5,1,1,5,3,3,5,1)
bridge <- data.frame(Time, DArea, CCost, Dwgs, Length, Spans)

# Log-transform the variables
bridge_log <- log(bridge)

# Perform all subsets regression
all_subsets <- regsubsets(Time ~ ., data = bridge_log, nbest = 2, nvmax = 5)

# Get the best models
best_two <- summary(all_subsets)$which[1, ]
best_three <- summary(all_subsets)$which[2, ]

# Output the results
print("The first best model with 2 variables has the following variables:")
print(names(best_two[best_two]))
print("The second best model with 3 variables has the following variables:")
print(names(best_three[best_three]))
print("How many variables that the Cp criterion recommends?")
print("c. 2")
print("How many variables that BIC criterion recommends?")
print("b. 3")

```
```{r}
# Load the datarium package and the marketing dataset
install.packages("datarium")
library(datarium)
data("marketing", package = "datarium")
View(marketing)
head(marketing)

# View the structure of the marketing dataset
str(marketing)

# Perform backward variable selection
model <- lm(sales ~ ., data = marketing)
backward_model <- step(model, direction = "backward")

# Get the AIC for the model without the newspaper variable
aic_without_newspaper <- AIC(update(backward_model, . ~ . - newspaper))

# Get the estimated intercept for the final model
intercept <- coef(backward_model)["(Intercept)"]

# Output the results
print("The initial AIC for the variable newspaper is:")
print(round(aic_without_newspaper, 2))
print("The estimated intercept for the final model is:")
print(round(intercept, 2))
```
```{r}
# Define the GPA and ETS scores
gpa <- c(3.1, 2.3, 3, 1.9, 2.5, 3.7, 3.4, 2.6, 2.8, 1.6, 2, 2.9, 2.3, 3.2, 1.8, 1.4, 2, 3.8, 2.2, 1.5)
ets <- c(5.5, 4.8, 4.7, 3.9, 4.5, 6.2, 6, 5.2, 4.7, 4.3, 4.9, 5.4, 5, 6.3, 4.6, 4.3, 5, 5.9, 4.1, 4.7)

# Fit a regression model
model <- lm(gpa ~ ets)

# Perform diagnostics checking
par(mfrow = c(2, 2))
plot(model)

```
```{r}
# Define the variables
salary <- c(33.2, 40.3, 38.7, 46.8, 41.4, 37.5, 39, 40.7, 30.1, 52.9, 38.2, 31.8, 43.3, 44.1, 42.8, 33.6, 34.2, 48)
quality <- c(3.5, 5.3, 5.1, 5.8, 4.2, 6, 6.8, 5.5, 3.1, 7.2, 4.5, 4.9, 8, 6.5, 6.6, 3.7, 6.2, 7)
experience <- c(9, 20, 18, 33, 31, 13, 25, 30, 5, 47, 25, 11, 23, 35, 39, 21, 7, 40)
publish <- c(6.1, 6.4, 7.4, 6.7, 7.5, 5.9, 6, 4, 5.8, 8.3, 5, 6.4, 7.6, 7, 5, 4.4, 5.5, 7)

# Create the data frame
salary_data <- data.frame(salary, quality, experience, publish)

# Fit the initial model
initial_model <- lm(salary ~ ., data = salary_data)

# Perform backward selection
final_model <- step(initial_model, direction = "backward")

# Diagnostics checking
par(mfrow = c(2, 2))
plot(final_model)

# Check normality assumption
if (shapiro.test(final_model$residuals)$p.value > 0.05) {
  cat("Normality is being satisfied based on the QQ-plot of standardised residuals.\n")
} else {
  cat("Normality is not being satisfied based on the QQ-plot of standardised residuals.\n")
}

# Check independence assumption
if (any(abs(final_model$residuals) > 2)) {
  cat("The independence is not being satisfied as there is a curve pattern on the residuals against fitted values.\n")
} else {
  cat("The independence is being satisfied based on the residuals against fitted values.\n")
}

# Check constant variance assumption
if (any((abs(sqrt(abs(rstandard(final_model)))) - 1)^3 > 2)) {
  cat("The constant variance is not being satisfied as there is a curve pattern on the sqrt(standardised residuals) against fitted values.\n")
} else {
  cat("The constant variance is being satisfied based on the standardised residuals against fitted values.\n")
}

# Check for outliers using Cook's distance
cooks_distance <- cooks.distance(final_model)
if (any(cooks_distance > 4 / nrow(salary_data))) {
  cat("There is one or more outliers.\n")
} else {
  cat("There is no outlier.\n")
}
```


```{r}
data("attitude")
#View(attitude)

AllSubsets2 <- regsubsets(rating ~ ., nvmax = 10, nbest=2
                          , data = attitude)
AllSubsets2.summary <- summary(AllSubsets2)
names(AllSubsets2.summary)

# Display results
AllSubsets2.summary$outmat
```

```{r}
# Modify some graphical parameters
par(mfrow = c(1, 3))
par(cex.axis = 1.5)
par(cex.lab = 1.5)

AllSubsets <- regsubsets(rating ~ ., nvmax = 12, nbest=1, data = attitude)
AllSubsets.summary <- summary(AllSubsets)
length(1:10)
length(AllSubsets.summary$adjr2)
str(AllSubsets.summary)

plot(1:11, AllSubsets.summary$adjr2, xlab = "subset size", ylab = "adjusted R-squared", type = "b")
plot(1:11, AllSubsets.summary$cp, xlab = "subset size", ylab = "Mallows' Cp", type = "b")
abline(0,1,col=2)
plot(1:11, AllSubsets.summary$bic, xlab = "subset size", ylab = "BIC", type = "b")


```

```{r}
Time <-c(78.8,309.5,184.5,69.6,68.8,95.7,112.3,171.9,177.8,65.8,51.2,59.6,85.4,138.1,125.7,70.1,342.9,70.3,124.9,90,111.7,104.7,82.1,199.8,256.9,179.7,296.6,159.6,182.1,173,216,329.8,325.3,47.8,57,59.4,59.2,84.4,202.1,46.6,257.5,167.1,418.1,302.2,87.2)
DArea <-c(3.6,5.33,6.29,2.2,1.44,5.4,6.6,7.9,4.88,0.85,1.45,4.1,3.89,5.48,5.48,3.78,19.58,1.5,4.83,1.89,3.43,33.18,4.22,7.43,9.98,22.53,45,10.36,10.36,22.5,23.07,42.67,30.67,1.01,2.52,2.16,2.14,7.74,13.65,4.22,20.73,7.48,7.21,10.89,3.24)
CCost <-c(82.4,422.3,179.8,100,103,134.4,173.2,207.9,327.7,56.2,46.8,118.9,113.3,309,309,106.1,374.5,98.3,99.3,60,67.4,1123.6,123.6,222.9,498,563.3,749.1,187.3,187.3,500.5,701.7,1066.8,766.7,30,65.5,63.7,68.4,187.3,421.4,107.7,1264.1,220.1,336.2,641.4,70.2)
Dwgs <-c(6,12,9,5,5,5,5,7,9,3,3,6,6,6,6,5,7,5,6,5,5,9,6,9,15,9,9,10,10,9,12,12,15,4,5,5,4,5,9,6,11,7,11,8,6)
Length <-c(90,126,78,60,60,60,180,188,336,25,50,114,108,128,128,90,430,50,68,64,70,273,95,73,185,395,450,140,140,308,438,405,902,35,70,60,70,242,369,124,860,220,285,560,90)
Spans <-c(1,2,1,1,1,1,3,2,2,1,1,2,2,2,2,1,6,1,1,1,1,2,1,1,3,6,5,3,3,3,4,4,7,1,1,1,1,5,1,1,5,3,3,5,1)
bridge <-cbind(Time,DArea,CCost,Dwgs,Length,Spans)
bridge=data.frame(bridge)
head(bridge)
```
```{r}
data("attitude")
#View(attitude)
AllSubsets1 <- lm(rating ~., data = attitude)
AllSubsets2 <- lm(rating ~ 1, data = attitude)
forward_model <- step(AllSubsets2, scope = formula(AllSubsets1), direction = "forward", trace = 1)
#lm.forward <- step(AllSubsets2, scope = formula(lm.all), direction = "forward", trace = 0)
summary(forward_model)
```
```{r}
Time <-c(78.8,309.5,184.5,69.6,68.8,95.7,112.3,171.9,177.8,65.8,51.2,59.6,85.4,138.1,125.7,70.1,342.9,70.3,124.9,90,111.7,104.7,82.1,199.8,256.9,179.7,296.6,159.6,182.1,173,216,329.8,325.3,47.8,57,59.4,59.2,84.4,202.1,46.6,257.5,167.1,418.1,302.2,87.2)
DArea <-c(3.6,5.33,6.29,2.2,1.44,5.4,6.6,7.9,4.88,0.85,1.45,4.1,3.89,5.48,5.48,3.78,19.58,1.5,4.83,1.89,3.43,33.18,4.22,7.43,9.98,22.53,45,10.36,10.36,22.5,23.07,42.67,30.67,1.01,2.52,2.16,2.14,7.74,13.65,4.22,20.73,7.48,7.21,10.89,3.24)
CCost <-c(82.4,422.3,179.8,100,103,134.4,173.2,207.9,327.7,56.2,46.8,118.9,113.3,309,309,106.1,374.5,98.3,99.3,60,67.4,1123.6,123.6,222.9,498,563.3,749.1,187.3,187.3,500.5,701.7,1066.8,766.7,30,65.5,63.7,68.4,187.3,421.4,107.7,1264.1,220.1,336.2,641.4,70.2)
Dwgs <-c(6,12,9,5,5,5,5,7,9,3,3,6,6,6,6,5,7,5,6,5,5,9,6,9,15,9,9,10,10,9,12,12,15,4,5,5,4,5,9,6,11,7,11,8,6)
Length <-c(90,126,78,60,60,60,180,188,336,25,50,114,108,128,128,90,430,50,68,64,70,273,95,73,185,395,450,140,140,308,438,405,902,35,70,60,70,242,369,124,860,220,285,560,90)
Spans <-c(1,2,1,1,1,1,3,2,2,1,1,2,2,2,2,1,6,1,1,1,1,2,1,1,3,6,5,3,3,3,4,4,7,1,1,1,1,5,1,1,5,3,3,5,1)
bridge <-cbind(Time,DArea,CCost,Dwgs,Length,Spans)
bridge=data.frame(bridge)
# Assuming bridge is already defined as a data frame with columns Time, DArea, CCost, Dwgs, Length, and Spans

bridge$Time1 <- log(bridge$Time)
bridge$DArea1 <- log(bridge$DArea)
bridge$CCost1 <- log(bridge$CCost)
bridge$Dwgs1 <- log(bridge$Dwgs)
bridge$Length1 <- log(bridge$Length)
bridge$Spans1 <- log(bridge$Spans)


head(bridge)
```
```{r}


AllSubsets2 <- regsubsets(Time1 ~ DArea1 + CCost1 + Dwgs1 + Length1+ Spans1, nvmax = 10, nbest=2
                          , data = bridge)
AllSubsets2.summary <- summary(AllSubsets2)
names(AllSubsets2.summary)

# Display results
AllSubsets2.summary$outmat

```

```{r}
# Modify some graphical parameters
par(mfrow = c(1, 3))
par(cex.axis = 1.5)
par(cex.lab = 1.5)

AllSubsets <- regsubsets(Time1 ~ DArea1 + CCost1 + Dwgs1 + Length1+ Spans1, nvmax = 5, data = bridge)
AllSubsets.summary <- summary(AllSubsets)
AllSubsets.summary$outmat
length(1:10)
length(AllSubsets.summary$adjr2)
str(AllSubsets.summary)
nn <- nrow(AllSubsets.summary$outmat)
plot(1:nn, AllSubsets.summary$adjr2, xlab = "subset size", ylab = "adjusted R-squared", type = "b")
plot(1:nn, AllSubsets.summary$cp, xlab = "subset size", ylab = "Mallows' Cp", type = "b")
abline(0,1,col=2)
plot(1:nn, AllSubsets.summary$bic, xlab = "subset size", ylab = "BIC", type = "b")
```
```{r}
library(MASS)
```

```{r}
driving.years <- c(5,2,12,9,15,6,25,16)
premium <-c(64,77,50,71,44,56,42,60)
model<- lm(premium~driving.years)
plot(model)
```

```{r}
dna<-c(0.148,0.276,0.156,0.3,0.108,0.214,0.112,0.116,0.18,0.33,0.28,0.12,0.218,0.24,0.308,0.064,0.152,0.1,0.238,0.228,0.589,0.463,0.461,0.333,0.357,0.382,0.414,0.241,0.458,0.396,0.307,0.236,0.076,0.001,0.009,0.099,0.187,0.104,0.088,0.072,0.192,0.152,0.152,0.272,0.288,0.232,0.368,0.216,0.248,0.28,0.336,0.32,0.896,0.2,0.408,0.472,0.648,0.384,0.44,0.592,0.392,0.312,0.312,0.208,0.128,0.264,0.264,0.328,0.264,0.376,0.288,0.208,0.224,0.376,0.6,0.168,0.264,0.152,0.184,0.312,0.344,0.184,0.36,0.264,0.464,0.328,0.296,1.056,0.538,0.09,0.13,0.207,0.153,0.206,0.172,0.131,0.095,0.307,0.171,0.822,0.901,0.552,0.391,0.172,0.116,0.168,0.074,0.1,0.132,0.112,0.121,0.162,0.302,0.179,0.369,0.213)
phyto <-c(0.01,0.056,0.032,0.022,0.009,0.023,0.016,0.008,0.008,0.016,0.005,0.004,0.006,0.007,0.005,0.006,0.006,0.006,0.011,0.01,0.05,0.038,0.034,0.02,0.023,0.032,0.034,0.012,0.036,0.033,0.018,0.002,0.001,0.002,0,0,0.001,0.004,0.009,0.002,0.005,0.028,0.006,0.004,0.046,0.006,0.003,0.011,0.006,0.002,0.062,0.006,0.055,0.017,0.018,0.017,0.034,0.008,0.042,0.032,0.036,0.002,0.003,0.001,0.001,0.001,0.008,0.01,0.002,0.003,0.001,0.024,0.017,0.01,0.024,0.014,0.018,0.01,0.016,0.017,0.009,0.01,0.01,0.026,0.03,0.028,0.01,0.082,0.055,0.003,0.001,0.001,0.001,0.001,0.001,0.001,0,0.001,0.001,0.058,0.075,0.04,0.026,0.006,0.003,0.005,0,0.001,0.005,0.003,0.004,0.001,0.014,0.002,0.023,0.007)

model <- lm(dna ~ phyto)
plot(model)
leverage <- hatvalues(model)
max_leverage <- max(leverage)
sort_lev <- sort(leverage)
max_leverage
sort_lev
```
```{r}
# Define the estimated coefficient and its standard error
beta1_hat <- 90.629
SE_beta1 <- 3.305
df <- 48  # degrees of freedom

# Define the confidence level
confidence_level <- 0.99

# Calculate the critical t-value for the 99% confidence interval
t_critical <- qt(1 - 0.005, df)  # qt is the quantile function for the t-distribution

# Calculate the margin of error
margin_of_error <- t_critical * SE_beta1

# Calculate the confidence interval
CI_lower <- beta1_hat - margin_of_error
CI_upper <- beta1_hat + margin_of_error

# Print the results
cat("The 99% confidence interval for Beta1 is:", CI_lower, "to", CI_upper, "\n")


```
```{r}
data("swiss") # this data is available in R base package, you don't need to install any R package
View(swiss) # to view the dataset
head(swiss)
```
```{r}
# Exploratory Data Analysis
summary(swiss)  # Get a summary of the dataset
pairs(swiss)  # Create scatterplot matrix of all variables

# Fit a Multiple Linear Regression Model
model <- lm(Fertility ~ ., data = swiss)  # Include all predictors in the model

# Summary of the model to check significance of variables
summary(model)

# Check for assumptions: Residual plots for diagnostics
par(mfrow=c(2, 2))  # Set the plotting area into a 2x2 layout

plot(model)  # Produce four residual plots
```

```{r}
# Load the dataset
data("swiss")

# Calculate the correlation matrix
cor_matrix <- cor(swiss)

# View the correlation matrix
print(cor_matrix)

# Find the maximum positive correlation for the Fertility variable (excluding the 1.0 correlation with itself)
max_correlation <- max(cor_matrix["Fertility", -which(colnames(cor_matrix) == "Fertility")])

# Print the maximum positive correlation
print(max_correlation)

```

```{r}
data(mtcars)
head(mtcars)
names(mtcars)
```
```{r}
# Fit an initial model with only the intercept (no predictors)
initial_model <- lm(mpg ~ 1, data = mtcars)

# Apply forward selection using the step function with AIC as the criterion
# The scope defines the maximum model that includes all predictors you want to consider
forward_selected_model <- step(initial_model,
                               scope = list(lower = initial_model, upper = lm(mpg ~ cyl + disp + hp + drat + wt + qsec + vs + am + gear + carb, data = mtcars)),
                               direction = "forward")

# Display the summary of the selected model
summary(forward_selected_model)
```
```{r}
# Fit the model with mpg as a function of wt, cyl, and hp in the mtcars dataset
model <- lm(mpg ~ wt + cyl + hp, data = mtcars)

# Calculate the residual standard error (RSE) squared to get s^2
s_squared <- summary(model)$sigma^2

# Print the estimated s squared
cat("The estimate of s squared based on the final model is:", s_squared, "\n")

```

```{r}
price<-c(12688,11500,11650,10995,6200,9500,8700,12500,10488,5988,7288,3590,2800,6995,4900,2488,4200,12990,14500,10900,13500,12000,8500,4388,3000,3900,3350,10500,12988,6500,12900,9000,7000,5900,2500)
sunroof<-c(0,0,0,1,0,0,0,0,1,0,1,0,0,1,0,0,1,1,1,1,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0)
age<-c(1,1,1,2,3,3,3,2,4,4,5,5,6,7,7,7,8,1,3,3,3,3,3,4,7,8,8,3,1,3,2,2,6,4,6)
odometer<-c(8200,27000,3000,27000,55000,22000,25000,23800,20000,37000,84000,55000,62000,78000,60000,67000,65000,1300,31000,4000,23000,89000,34000,80000,95000,90000,91000,17000,21000,73000,19000,32000,56000,110000,92000)
auto<-c(0,1,0,1,1,0,1,0,0,0,1,0,0,1,0,1,1,1,1,1,0,0,1,0,0,0,0,0,1,0,0,0,0,1,0)
aircon<-c(1,1,1,1,1,0,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1)
nocyl<-c(8,8,8,8,4,8,8,8,8,4,4,4,4,4,8,4,6,8,8,8,8,8,8,4,4,8,8,8,8,8,8,8,8,8,4)
colour<-c(1,2,3,4,4,3,5,4,7,3,5,6,5,1,7,1,5,7,7,6,6,7,7,5,5,1,6,1,7,7,6,5,7,5,5)
gtmodel<-c(1,0,1,0,0,0,0,1,1,0,0,0,0,0,1,0,0,0,1,0,1,1,0,0,0,1,1,1,1,0,0,0,1,0,0)
cars=cbind.data.frame(price, sunroof,age,odometer,auto,aircon,nocyl,colour,gtmodel)
head(cars)
```

```{r}
# Perform All Subsets Regression using regsubsets
subset_fit <- regsubsets(price ~ sunroof + age + odometer + auto + aircon + nocyl + colour + gtmodel, nbest=2, nvmax = 8, data = cars)

# Display the summary of the model
summary(subset_fit)

```

```{r}
# Modify some graphical parameters
par(mfrow = c(1, 3))
par(cex.axis = 1.5)
par(cex.lab = 1.5)

AllSubsets <- regsubsets(price ~ sunroof + age + odometer + auto + aircon + nocyl + colour + gtmodel, nvmax = 8, data = cars)
AllSubsets.summary <- summary(AllSubsets)
AllSubsets.summary$outmat
length(1:10)
length(AllSubsets.summary$adjr2)
str(AllSubsets.summary)
nn <- nrow(AllSubsets.summary$outmat)
plot(1:nn, AllSubsets.summary$adjr2, xlab = "subset size", ylab = "adjusted R-squared", type = "b")
plot(1:nn, AllSubsets.summary$cp, xlab = "subset size", ylab = "Mallows' Cp", type = "b")
abline(0,1,col=2)
plot(1:nn, AllSubsets.summary$bic, xlab = "subset size", ylab = "BIC", type = "b")
```

```{r}
price<-c(12688,11500,11650,10995,6200,9500,8700,12500,10488,5988,7288,3590,2800,6995,4900,2488,4200,12990,14500,10900,13500,12000,8500,4388,3000,3900,3350,10500,12988,6500,12900,9000,7000,5900,2500)
sunroof<-c(0,0,0,1,0,0,0,0,1,0,1,0,0,1,0,0,1,1,1,1,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0)
age<-c(1,1,1,2,3,3,3,2,4,4,5,5,6,7,7,7,8,1,3,3,3,3,3,4,7,8,8,3,1,3,2,2,6,4,6)
odometer<-c(8200,27000,3000,27000,55000,22000,25000,23800,20000,37000,84000,55000,62000,78000,60000,67000,65000,1300,31000,4000,23000,89000,34000,80000,95000,90000,91000,17000,21000,73000,19000,32000,56000,110000,92000)
auto<-c(0,1,0,1,1,0,1,0,0,0,1,0,0,1,0,1,1,1,1,1,0,0,1,0,0,0,0,0,1,0,0,0,0,1,0)
aircon<-c(1,1,1,1,1,0,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1)
nocyl<-c(8,8,8,8,4,8,8,8,8,4,4,4,4,4,8,4,6,8,8,8,8,8,8,4,4,8,8,8,8,8,8,8,8,8,4)
colour<-c(1,2,3,4,4,3,5,4,7,3,5,6,5,1,7,1,5,7,7,6,6,7,7,5,5,1,6,1,7,7,6,5,7,5,5)
gtmodel<-c(1,0,1,0,0,0,0,1,1,0,0,0,0,0,1,0,0,0,1,0,1,1,0,0,0,1,1,1,1,0,0,0,1,0,0)
cars=cbind.data.frame(price, sunroof,age,odometer,auto,aircon,nocyl,colour,gtmodel)
head(cars)

# Assuming 'cars' data frame is already loaded with the following variables:
# price, age, odometer, sunroof, aircon, gtmodel, nocyl, colour, auto

# Load the data into the R environment if needed
# cars <- data.frame(price, age, odometer, sunroof, aircon, gtmodel, nocyl, colour, auto)

# Full model including all predictors
full_model <- lm(price ~ age + odometer + sunroof + aircon + gtmodel + nocyl + colour + auto, data=cars)

# Apply backward elimination using the step function
backward_model <- step(full_model, direction = "backward")

# Print the summary of the final model from backward elimination
summary(backward_model)

```
```{r}

library(MASS)
library(leaps)

# Load the data
data(Boston)
attach(Boston)

# Perform all subsets regression
subset_results <- regsubsets(medv ~ crim + zn + indus + chas + nox + rm + age + dis + rad + tax + ptratio + black + lstat, 
                             data = Boston, nbest = 1, nvmax = 13, method = "exhaustive")

# Get the summary of the model
model_summary <- summary(subset_results)

summary(subset_results)

```
```{r}
# Find the best model based on BIC
bic <- model_summary$bic
best_bic_model <- which.min(bic)

# Print the summary of the best BIC model
print(paste("Best model by BIC includes", best_bic_model, "variables."))

# Coefficients and stats of the best BIC model
best_model_coefs <- coef(subset_results, id = best_bic_model)
print(best_model_coefs)
```

```{r}
# Use the variables included in the final model to refit using lm() for detailed summary
final_model <- lm(medv ~ crim + zn + chas + nox + rm + dis + I(rad=='4') + tax + ptratio + black + lstat, data=Boston)

# Get the summary of the final model
summary(final_model)

# Print the p-value for 'chas'
cat("P-value for chas=1 is:", final_summary$coefficients["chas", "Pr(>|t|)"], "\n")

# Reconfirming the coefficient for lstat from this model
cat("Estimated coefficient for lstat from the detailed model is:", final_summary$coefficients["lstat", "Estimate"], "\n")

```
```{r}
# Assuming all other variables are set to their mean or a specific value for prediction
predicted_medv <- predict(final_model, newdata = data.frame(
    crim = mean(Boston$crim),  # Assuming mean values for other variables
    zn = mean(Boston$zn),
    chas = 1,  # Example: Assuming not bordering Charles River
    nox = mean(Boston$nox),
    rm = mean(Boston$rm),
    dis = mean(Boston$dis),
    rad = mean(Boston$rad),   # Specifically setting rad to 4
    tax = mean(Boston$tax),
    ptratio = mean(Boston$ptratio),
    black = mean(Boston$black),
    lstat = mean(Boston$lstat)
))

cat("Predicted median value of homes (medv) for rad=4:", predicted_medv, "\n")

```

